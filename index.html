<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Multi-hand LLM-Based Grasp Generation with Semantic Information Guided">
  <meta name="keywords" content="Robotics,Grasp Generation,Multi-hand,Dextrous Hand">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Multi-GraspLLM: A Multimodal LLM for Multi-Hand Semantic Guided Grasp Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    .interpolation-image {
      width: 100%; /* 确保图片最大化适应容器 */
      height: auto; /* 保持宽高比 */
      max-width: 100%;  /* 不超过容器宽度 */
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://arxiv.org/abs/2410.08901">
            SegGrasp
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Nerfies: Deformable Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="">Haosheng Li</a><sup>1*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=6-bYm5EAAAAJ&hl=zh-CN&oi=ao">Weixin Mao</a><sup>2*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=JBMI5yQAAAAJ&hl=zh-CN&oi=ao">Weipeng Deng</a><sup>3</sup>,</span>
            <span class="author-block"><a href="">Chenyu Meng</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=bzzBut4AAAAJ&hl=zh-CN&oi=ao">Haoqiang Fan</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=YI0sRroAAAAJ&hl=zh-CN&oi=ao">Tiancai Wang</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=XhyKVFMAAAAJ&hl=zh-CN&oi=ao">Ping Tan</a><sup>5</sup></span>
            <span class="author-block"><a href="">Hongan Wang</a><sup>1</sup></span>
            <span class="author-block"><a href="https://www.idengxm.com/">Xiaoming Deng</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute of Software, Chinese Academy of Sciences</span>
            <span class="author-block"><sup>2</sup>Waseda University</span>
            <span class="author-block"><sup>3</sup>Hongkong University</span>
            <span class="author-block"><sup>4</sup>MEGVII Technology</span>
            <span class="author-block"><sup>5</sup>Hong Kong University of Science and Technology </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<div class="content has-text-justified"></div>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multi-hand semantic grasp generation aims to generate feasible and semantically appropriate grasp poses for different robotic hands based on natural language instructions. 
            Although the task is highly valuable, due to the lack of multi-hand grasp datasets with fine-grained contact description between robotic hands and objects, it is still a long-standing difficult task. 
            In this paper, we present Multi-GraspSet, the first large-scale multi-hand grasp dataset with automatically contact annotations. 
            Based on Multi-GraspSet, we propose Multi-GraspLLM, a unified language-guided grasp generation framework. It leverages large language models (LLM) to handle variable-length sequences, generating grasp poses for diverse robotic hands in a single unified architecture. 
            Multi-GraspLLM first aligns the encoded point cloud features and text features into a unified semantic space.
             It then generates grasp bin tokens which are subsequently converted into grasp pose for each robotic hand via hand-aware linear mapping. 
            The experimental results demonstrate that our approach significantly outperforms existing methods on Multi-GraspSet.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dataset Construction</h2>
        <div class="content has-text-justified">
          <p>
            The initial unified grasp generation produces physically stable grasps. Then, through two levels of annotations, we generate pair data containing basic conversation with corresponding grasp pose for each robotics hand.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full-width has-text-centered">
            <img src="./static/picture/dataset_construction.png" class="interpolation-image" alt="Dataset Construction Image"/>
            <p>Dataset Construction</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="columns is-centered is-vcentered">
          <div class="column is-half has-text-centered">
            <img src="./static/picture/train_data_01.png" class="interpolation-image" alt="Grasp Visualization Image 1"/>
            <p>Grasp Visualization 1</p>
          </div>
          <div class="column is-half has-text-centered">
            <img src="./static/picture/vis_dataset_grasp_output_01.png" class="interpolation-image" alt="Grasp Visualization Image 2"/>
            <p>Grasp Visualization 2</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Multi-GraspLLM</h2>
        <div class="content has-text-justified">
          <p>
            The point encoder extracts point clouds from objects and maps them with language descriptions into the same latent space. The LLM backbone then generate grasp bin tokens as output. Finally, we convert these grasp bin tokens into corresponding grasp angles for each robotic hand.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full-width has-text-centered">
            <img src="./static/picture/pipline-squeeze_01.png" class="interpolation-image" alt="Dataset Construction Image"/>
            <p>Pipeline of Multi-GraspLLM</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Visualization</h2>
        <div class="content has-text-justified">
          <p>
            
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full-width has-text-centered">
            <img src="./static/picture/Supp_visDataset.png" class="interpolation-image" alt="Dataset Construction Image"/>
            <p>Visualization of the Multi-GraspLLM Results/p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
